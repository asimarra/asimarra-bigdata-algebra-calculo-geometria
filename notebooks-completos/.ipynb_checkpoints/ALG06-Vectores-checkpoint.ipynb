{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96358408",
   "metadata": {},
   "source": [
    "<img src=\"images/keepcoding.png\" width=200 align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe40bd50",
   "metadata": {},
   "source": [
    "# Vectores\n",
    "\n",
    "Imagina que estás jugando al billar. Es importante la fuerza con la que golpeas la bola, pero también la dirección en la que lo haces.\n",
    "\n",
    "<img src=\"./images/billar.jpg\" style=\"width: 250px;\"/>\n",
    "\n",
    "Los vectores en matemáticas son esas flechas que muestran cómo se mueve algo y con qué fuerza lo hace. Esto los diferencia de las magnitudes llamadas **escalares**, que se representan con un solo número. Veamos más ejemplos:\n",
    "\n",
    "- La temperatura de una habitación es una magnitud escalar, por ejemplo, 24 grados\n",
    "- El peso de una persona es un escalar, por ejemplo, 60kg\n",
    "- El viento sopla con una determinada magnitud y en una dirección determinada, es una magnitud vectorial, por ejemplo 40km/h dirección sur\n",
    "- La velocidad de un coche es una magnitud vectorial, por ejemplo, 100km/h dirección A Coruña"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e155ca07",
   "metadata": {},
   "source": [
    "## 1. Definición\n",
    "\n",
    "Un vector (real) de dimensión n es un ente matemático que viene representado por una tupla de números reales (que se llaman componentes del vector). \n",
    "\n",
    "<center>$v = (a_{1}, a_{2}, a_{3}, ... a_{n})$ donde $v \\in {R}^{n}$</center>\n",
    "\n",
    "Un vector también se puede ver desde el punto de vista de la geometría como vector geométrico. En este sentido, un vector es cualquier ente matemático que se puede representar mediante un segmento de recta orientado dentro del espacio euclidiano.\n",
    "\n",
    "Para definir un vector necesitamos:\n",
    "\n",
    "- Dirección, sentido, módulo y punto de aplicación\n",
    "\n",
    "o bien\n",
    "\n",
    "- Sus componentes $a_i$\n",
    "\n",
    "<img src=\"./images/vector.png\" alt=\"vector\" style=\"width: 500px;\"/>\n",
    "\n",
    "Vemos este vector en el espacio bidimensional:\n",
    "\n",
    "- Su módulo es la longitud de la flecha, que es un escalar. El módulo será mayor cuanto más grande sea la flecha\n",
    "- Su dirección viene representada por la recta roja. Lo podemos medir mediante un ángulo con un eje horizontal imaginario\n",
    "- Su sentido viene representado por la orientación de la flecha y hay dos posibles y opuestas para cada dirección\n",
    "- Si se trata de un vector fijo en el plano, podemos representar su origen con un punto. Por ejemplo, el vector que va de A a B será $\\vec{AB}$\n",
    "\n",
    "Podemos representar el vector en un plano cartesiano bidimensional usando dos ejes coordenados:\n",
    "\n",
    "<img src=\"./images/vector-coord.png\" alt=\"vector\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "En este caso, además del módulo, dirección y sentido, vemos que el origen del vector se ha hecho coincidir con el origen de coordenadas y que podemos ver las componentes en cada uno de los ejes, por lo que $\\vec{v}= (v_x, v_y)$.\n",
    "\n",
    "En caso de estar en el espacio (tridimensional), necesitaríamos una componente más, y el dibujo también tendría una dimensión más. Sin embargo, la represntación con una flecha con módulo, dirección y sentido se mantiene.\n",
    "\n",
    "<img src=\"./images/vector-coord-3.png\" alt=\"vector\" style=\"width: 500px;\"/>\n",
    "\n",
    "Podemos distinguir entre vectores fijos y libres: los últimos no están aplicados en un punto determinado, mientras que los primeros sí.\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"> Notación: los vectores suelen representarse como $\\vec{v}$ o con negrita y su módulo como $|v|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db011de",
   "metadata": {},
   "source": [
    "## 2. Uso con python y operaciones elementales\n",
    "\n",
    "Utilizaremos los vectores en Python para almacenar información (numérica) de todo tipo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb7cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/raquel/Documents/KC/venv/lib/python3.10/site-packages (1.26.4)\n",
      "[2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "import numpy as np\n",
    "# Creación de un vector con numpy\n",
    "v = np.array([2, 3, 4, 5, 6, 7])\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85857b4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 5, 6, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2, 3, 4, 5, 6, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d7fc73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[2, 3, 4, 5, 6, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a2fb7f-402a-4865-8559-2deb31f2fe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffea4e97-3dde-43be-b574-f0bc805ded47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5bf2485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En el futuro vamos a poder guardar elementos multidimensionales, por lo que aprendemos a usar shape\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4661ef41",
   "metadata": {},
   "source": [
    "### 2.1 Suma y resta de vectores\n",
    "\n",
    "El **vector suma** está definido por:\n",
    "\n",
    "\n",
    "<center>$[u_{1}, u_{2}, ..., u_{n}] + [v_{1}, v_{2}, ..., v_{n}] = [u_{1}+v_{1}, u_{2}+v_{2}, ..., u_{n}+v_{n}]$</center>\n",
    "\n",
    "Para cualesquiera vectores **u**, **v**, **w**, se tiene:\n",
    "* Propiedad asociativa: $(u+v)+w=u+(v+w)$\n",
    "* Propiedad conmutativa: $u+v=v+u$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c6a560b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np # !pip install numpy\n",
    "\n",
    "x_np = np.array([1, 4, 2])\n",
    "y_np = np.array([7, 4, 2])\n",
    "\n",
    "x_np + y_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9800f15f",
   "metadata": {},
   "source": [
    "Es importante no tratar las listas de python como si fuesen vectores, porque el operador suma lo que hará será concatenarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "191c8c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 2, 7, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 4, 2]\n",
    "b = [7, 4, 2]\n",
    "\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f599bd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2f66490",
   "metadata": {},
   "source": [
    "De forma similar, el vector resta se define como:\n",
    "\n",
    "<center>$[u_{1}, u_{2}, ..., u_{n}] - [v_{1}, v_{2}, ..., v_{n}] = [u_{1}-v_{1}, u_{2}-v_{2}, ..., u_{n}-v_{n}]$</center>\n",
    "\n",
    "Gráficamente el vector **-u** es el vector **u** con el sentido contrario de la flecha, por lo que podemos ver la resta como **u** - **v** = **u** + **-v** y usar el método gráfico que hemos visto para la suma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1d5bbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_np - x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6b889",
   "metadata": {},
   "source": [
    "Que una de las componentes sea negativa, gráficamente, solo quiere decir que la componente de ese eje va a ir en el sentido contrario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a30584",
   "metadata": {},
   "source": [
    "**IMPORTANTE**: No podemos sumar o restar vectores de distinta dimensión. Esto sería como intentar sumar una flecha en el plano con una en el espacio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ec0e31e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,) (2,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m z_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mx_np\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz_np\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,) (2,) "
     ]
    }
   ],
   "source": [
    "z_np = np.array([7, 4])\n",
    "x_np + z_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968f193",
   "metadata": {},
   "source": [
    "## 2.2 Producto de un escalar por un vector\n",
    "\n",
    "Dado un número $a$ y un vector $v$, la multiplicación viene definida por:\n",
    "<br>\n",
    "<center>$a \\cdot (v_{1}, v_{2}, ... v_{n}) = (a \\cdot v_{1}, a \\cdot v_{2}, ... a \\cdot v_{n})$</center>\n",
    "\n",
    "Dado un vector **v** y dos números cualesquiera $\\alpha$, $\\beta \\in \\mathbb{R}$, se tiene:\n",
    "* Propiedad asociativa: $\\alpha$($\\beta$**v**)=($\\alpha$$\\beta$)**v**  \n",
    "* Propiedad distributiva: $\\alpha$(**u**+**v**)=$\\alpha$**u**+ $\\alpha$**v**\n",
    "\n",
    "\n",
    "Con numpy podemos usar la multiplicación directamente, pero no es el caso si tratamos con listas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "618af0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 3, 12,  6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_np)\n",
    "3*x_np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45af8d5f",
   "metadata": {},
   "source": [
    "El vector resultante de la multiplicación por un escalar (que recordemos no es más que un número) es otro vector con la misma dirección, pero cuyo módulo se ha multiplicado por el escalar. En caso de que sea un número negativo, se invertiría también el sentido del vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c22de5a",
   "metadata": {},
   "source": [
    "## 2.3 Producto escalar o interior\n",
    "\n",
    "El producto escalar o interior entre dos vectores tiene como resultado un escalar (un número). De nuevo, necesitamos que los dos vectores tengan la misma dimensión, o lo que es lo mismo, el mismo número de componentes.\n",
    "\n",
    "Podemos imaginarlo como una manera de medir cuánto se parecen dos vectores o cuánto tienen en común en términos de dirección.\n",
    "\n",
    "Pensemos en dos flechas que representan dos vectores. El producto escalar sería como multiplicar la longitud de una de esas flechas por la proyección de la otra flecha sobre la primera. Si las flechas van en la misma dirección, el producto escalar es grande porque tienen mucho en común. Si están en direcciones diferentes o perpendiculares, el producto escalar es más pequeño o incluso puede ser cero porque hay menos similitud entre ellas.\n",
    "\n",
    "Por ejemplo, si estamos midiendo la fuerza que necesitas para empujar un objeto en la dirección exacta en la que queremos moverlo, el producto escalar de las fuerzas que aplicamos sería grande si empujas en la misma dirección que el movimiento y más pequeño si aplicamos la fuerza en una dirección diferente.\n",
    "\n",
    "\n",
    "Considerando dos vectores $\\overrightarrow{u}$ y $\\overrightarrow{v}$, el producto escalar viene definido por:\n",
    "\n",
    "\n",
    "<center>$\\overrightarrow{u} \\cdot \\overrightarrow{v} = \\sum_{i \\in D}\\overrightarrow{u}_{i} \\cdot \\overrightarrow{v}_{i} = u_{1} \\cdot v_{1} + u_{2} \\cdot v_{2} + ... u_{n} \\cdot v_{n}$</center>\n",
    "\n",
    "También puede escribirse de la siguiente forma:\n",
    "\n",
    "<center>$\\overrightarrow{u} \\cdot \\overrightarrow{v} = |\\overrightarrow{u}||\\overrightarrow{v}| \\cos \\theta $</center>\n",
    "\n",
    "Donde las barras indican el módulo de los vectores (la magnitud de la flecha, lo veremos más adelante!) y $\\theta$ es el ángulo que forman entre ellos (si los imaginamos como flechas).\n",
    "\n",
    "Las **propiedades algebraicas del producto escalar** son:  \n",
    "* **Propiedad conmutativa**: **u** · **v** = **v** · **u**  \n",
    "* **Homogeneidad**: (α u) · v = α (u · v)  \n",
    "* **Propiedad distributiva**: (v<sub>1</sub> + v<sub>2</sub>) · **x** = v<sub>1</sub> · **x** + v<sub>2</sub> · **x**  \n",
    "\n",
    "Existe un operador en numpy para el producto escalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e60bcd6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "u = np.array([1, 2, 3])\n",
    "v = np.array([4, 5, 6])\n",
    "\n",
    "v @ u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aee9a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2236150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([3, 2, 1])\n",
    "v = np.array([4, 5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d6efcf",
   "metadata": {},
   "source": [
    "¿Qué pasa si intentamos hacer el producto escalar con dos vectores de distinta dimensión?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65e65c44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3 is different from 2)"
     ]
    }
   ],
   "source": [
    "v @ u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4b3859",
   "metadata": {},
   "source": [
    "**Ejercicio**: Calcular el producto escalar sin usar numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "861dc476",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = [1, 2, 3, 4]\n",
    "v = [7, 4, 5, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defd54fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def producto_escalar(u,v):\n",
    "    accum = 0\n",
    "    for n,v in zip(u,v):\n",
    "        accum += n*v\n",
    "    return accum\n",
    "producto_escalar(u,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "177961cb-ab83-4544-ae1b-a2610f39ad36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(u,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f09358f7-2b98-4ee4-b87d-1566f1b0cbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(i*k for i, k in zip(u,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f37115b-ebd6-4b39-bbee-484f9f91a526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion\n",
      "1\n",
      "7\n",
      "Iteracion\n",
      "2\n",
      "4\n",
      "Iteracion\n",
      "3\n",
      "5\n",
      "Iteracion\n",
      "4\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i, k in zip(u,v):\n",
    "    print(\"Iteracion\")\n",
    "    print(i)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "148bd9de-eb3e-4e68-a3cb-bf4179f66a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x7fb2f071a500>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(u,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600f6200",
   "metadata": {},
   "source": [
    "### 2.3.1 Vectores ortogonales\n",
    "\n",
    "Dos vectores son ortogonales (geométricamente, perpendiculares) si y solo si su producto escalar es nulo. Si recordamos la fórmula del producto escalar, teníamos el coseno del ángulo que forman. Según la circunferencia trigonométrica, el coseno es 0 para un ángulo de 90 o 270.\n",
    "\n",
    "Por tanto, si dos vectores tienen magnitud no nula (vamos a ver en un momento lo que es esto con más detalle) y su producto escalar es 0, son perpendiculares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bbd2b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.array([3, 4])\n",
    "v2 = np.array([-4, 3])\n",
    "\n",
    "v1 @ v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac3b114",
   "metadata": {},
   "source": [
    "### 2.4 Norma de un vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb5bfdd",
   "metadata": {},
   "source": [
    "La norma de un vector es básicamente una medida de su tamaño o longitud, es decir, de la magnitud de la flecha. \n",
    "\n",
    "En términos simples, para nosotros va a ser como calcular la distancia desde el origen (el punto de partida) hasta el extremo del vector.\n",
    "\n",
    "Hay varios tipos de normas, y todas tienen que cumplir las siguientes propiedades:\n",
    "\n",
    "* $\\|v\\|$ es un número real no negativo.  \n",
    "* $\\|v\\|$ = 0 $\\leftrightarrow$ **v**=0.   \n",
    "* Para cualquier escalar $\\alpha$, $\\|\\alpha\\cdot v\\|$ = $| \\alpha | \\cdot$ $\\|v\\|$.  \n",
    "* $\\|u+v\\|$ ≤ $\\|u\\|$ + $\\|v\\|$ (desigualdad triangular)\n",
    "\n",
    "Algunas normas comúnmente utilizadas son:\n",
    "\n",
    "- Norma-1: $|x_1|+|x_2|+...+|x_n|$\n",
    "\n",
    "- Norma-2: $\\sqrt{|x_1|^2+|x_2|^2+...+|x_n|^2}$\n",
    "\n",
    "- Norma-infinito: $\\max(|x_1|, |x_2|,...,|x_n|)$\n",
    "\n",
    "Utilizaremos sobre todo la norma 2, también llamada norma euclídea. Es la raíz cuadrada del producto escalar del vector por sí mismo. \n",
    "\n",
    "<center>$||v|| =+ \\sqrt{v \\cdot v} = (\\sum_{i=1}^{n}x_{i}^2)^\\frac{1}{2}$</center>\n",
    "\n",
    "Por las propiedades del producto escalar, sabemos que va a ser un número positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7311940b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_array = np.array(u)\n",
    "v_array = np.array(v)\n",
    "np.linalg.norm(u_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b33800e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(u_array @ u_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f3b869",
   "metadata": {},
   "source": [
    "Hay más formas de calcularla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7dae06b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.477225575051661"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(sum(u_array*u_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ced4106",
   "metadata": {},
   "source": [
    "### 3.1 Ejemplo: objeto en movimiento\n",
    "\n",
    "Vamos a imaginar un objeto en movimiento con una velocidad inicial y una aceleración constante. Vamos a calcular su posición en diferentes momentos del tiempo utilizando ecuaciones de movimiento, que sabemos que son:\n",
    "\n",
    "$\\vec{x} = \\vec{x_0} + \\vec{v_0}t + {{1}\\over{2}} \\vec{a} t² $\n",
    "\n",
    "Donde vamos a usar un sistema de 3 ejes cartesianos (x, y, z) y:\n",
    "\n",
    "- $\\vec{x}$ será la posición (vector!) en un instante de tiempo\n",
    "- $\\vec{x_0}$ será la posición inicial para t=0, que también es un vector (puesto que necesitamos saber las tres componentes)\n",
    "- $\\vec{v_0}$ es la velocidad inicial del objeto para t=0\n",
    "- $\\vec{a}$ es la aceleración del objeto, que vamos a tomar como una magnitud vectorial constante, es decir, que no depende del tiempo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "68ff084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posición final después de 2 segundos:\n",
      "x:  7.0\n",
      "x:  7.6\n",
      "x:  6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Datos iniciales\n",
    "x_0 = np.array([0, 0, 0])\n",
    "v_0 = np.array([3, 4, 2])\n",
    "a = np.array([0.5, -0.2, 1])\n",
    "# Tiempo\n",
    "t = 2\n",
    "# Calcular la posición final utilizando las ecuaciones de movimiento\n",
    "\n",
    "posicion_final = x_0 + v_0*t + 0.5*a*t**2\n",
    "\n",
    "print(\"Posición final después de\", t, \"segundos:\")\n",
    "print(\"x: \", posicion_final[0])\n",
    "print(\"x: \", posicion_final[1])\n",
    "print(\"x: \", posicion_final[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a257c",
   "metadata": {},
   "source": [
    "Podemos ver cómo cambia la posición final en función de la velocidad y posición iniciales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922715f1",
   "metadata": {},
   "source": [
    "### 3.2 Ejemplo: procesamiento de lenguaje natural\n",
    "\n",
    "Además de múltiples ejemplos del mundo físico, los vectores tienen gran utilidad en el ámbito de PNL o procesamiento de lenguaje natural (NLP en inglés). \n",
    "\n",
    "El modelo más básico es la representación bag-of-words, que respresenta un texto como un conjunto no ordenado de palabras. No tiene en cuenta la relación entre las palabras, aunque sí que tiene en cuenta cuántas veces aparecen.\n",
    "\n",
    "Veamos un ejemplo. Primero vamos a crear una función para obtener el vocabulario de las oraciones, es decir, todas las palabras distintas que aparecen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8404b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Función para obtener el vocabulario único de las oraciones\n",
    "def obtener_vocabulario(oraciones):\n",
    "    palabras = set()\n",
    "    for oracion in oraciones:\n",
    "        palabras.update(oracion.split())\n",
    "    return list(palabras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20b52e4",
   "metadata": {},
   "source": [
    "Vamos a usar un par de oraciones de ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ebd7c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustan',\n",
       " 'ladra',\n",
       " 'Me',\n",
       " 'son',\n",
       " 'animales',\n",
       " 'perro',\n",
       " 'los',\n",
       " 'El',\n",
       " 'perros',\n",
       " 'Los',\n",
       " 'y']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de oraciones\n",
    "oraciones_ejemplo = [\n",
    "    \"El perro ladra\",\n",
    "    \"Me gustan los perros\",\n",
    "    \"Los perros y los perros son animales\"\n",
    "]\n",
    "\n",
    "# Obtener el vocabulario único de las oraciones\n",
    "vocabulario = obtener_vocabulario(oraciones_ejemplo)\n",
    "vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c4488",
   "metadata": {},
   "source": [
    "El siguiente paso sería crear un vector para cada oración, en función del vocabulario que hemos generado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2ef737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulario:  ['gustan', 'ladra', 'Me', 'son', 'animales', 'perro', 'los', 'El', 'perros', 'Los', 'y']\n",
      "Oración 1:  [0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "Oración 2:  [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
      "Oración 3:  [0. 0. 0. 1. 1. 0. 1. 0. 2. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Función para representar cada oración como un vector de frecuencia de palabras\n",
    "def representar_oraciones(oraciones, vocabulario):\n",
    "    representaciones = np.zeros((len(oraciones), len(vocabulario)))\n",
    "    for i, oracion in enumerate(oraciones): # para cada oracion\n",
    "        for palabra in oracion.split(): # dentro de cada oracion, cada palabra\n",
    "            if palabra in vocabulario: # busco si está en el vocabulario\n",
    "                indice = vocabulario.index(palabra) # si está, veo la posición en el vocabulario        \n",
    "                representaciones[i][indice] += 1\n",
    "    return representaciones\n",
    "# Representar las oraciones como vectores de frecuencia de palabras\n",
    "\n",
    "representaciones = representar_oraciones(oraciones_ejemplo, vocabulario)\n",
    "# Imprimir resultados\n",
    "print(\"Vocabulario: \", vocabulario)\n",
    "for i, vector in enumerate(representaciones):\n",
    "    print(f\"Oración {i+1}: \", vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b82cc14-812d-4e3a-ba8b-1b975bc9efa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d0c85718-285c-4ddd-9468-d0612554a7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gustan',\n",
       " 'ladra',\n",
       " 'Me',\n",
       " 'son',\n",
       " 'animales',\n",
       " 'gatos',\n",
       " 'perro',\n",
       " 'los',\n",
       " 'El',\n",
       " 'perros',\n",
       " 'Los',\n",
       " 'y']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4de385",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que normalmente en este tipo de representaciones se hace un tratamiento previo para quedarse con la raíz de la palabra, por ejemplo, \"perro\" y \"perros\" tendrían la misma raíz (esto se conoce como stemming). También se suelen quitar las palabras que no aportan significado, como \"el\", \"la\", \"de\", que se denominan \"stop words\". Existen librerías específicas que hacen este trabajo mucho más fácil, por ejemplo [nltk](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "962003db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/raquel/Documents/KC/venv/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/raquel/Documents/KC/venv/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/raquel/Documents/KC/venv/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /home/raquel/Documents/KC/venv/lib/python3.10/site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/raquel/Documents/KC/venv/lib/python3.10/site-packages (from nltk) (2024.5.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4856d6bd-a36e-49c7-8e35-984ee2cdf563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /home/raquel/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "08307a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(oraciones_ejemplo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3c07b707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['El', 'perro', 'ladra']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea39e76c",
   "metadata": {},
   "source": [
    "Este tipo de representación es muy útil, por ejemplo, podríamos crear un clasificador para determinar si un email es o no spam, usando una muestra conocida para entrenar. Como es de esperar, trabajar con vectores (números) nos permite usar muchos más modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
